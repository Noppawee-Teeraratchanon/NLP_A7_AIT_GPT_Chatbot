{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented generation (RAG)\n",
    "\n",
    "Introducing `AITBot`, an innovative chatbot designed to assist AIT information member to answer the question about AIT \n",
    "\n",
    "\n",
    "1. Retrieval (find the relevant sources related to AIT )\n",
    "2. Prompt (Design Prompt Template)\n",
    "3. Memory => let model to know previous answer of question\n",
    "4. Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #langchain library\n",
    "# !pip install langchain==0.1.6\n",
    "# !pip install langchain-community==0.0.19\n",
    "# #LLM\n",
    "# !pip install accelerate==0.25.0\n",
    "# !pip install transformers==4.36.2\n",
    "# !pip install bitsandbytes==0.41.2 \n",
    "# #Text Embedding\n",
    "# !pip install sentence-transformers==2.2.2\n",
    "# !pip install InstructorEmbedding==1.0.1\n",
    "# #vectorstore\n",
    "# !pip install pymupdf==1.23.8\n",
    "# !pip install faiss-gpu==1.7.2\n",
    "# !pip install faiss-cpu==1.7.4\n",
    "# !pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all relevant sources related to AIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieval\n",
    "\n",
    "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code). \n",
    "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
    "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
    "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
    "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Document Loaders \n",
    "I load text from AIT website and save them as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pdfkit\n",
    "import re\n",
    "\n",
    "def sanitize_filename(url):\n",
    "    # Remove special characters from the URL\n",
    "    filename = re.sub(r'[^a-zA-Z0-9_-]', '_', url)\n",
    "    return filename\n",
    "\n",
    "def crawl_website(url, visited_pages=set(), max_depth=3, html_directory='html_files'):\n",
    "    if max_depth == 0:\n",
    "        return\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Add the current URL to the visited pages set\n",
    "        visited_pages.add(url)\n",
    "        \n",
    "        # Save the page as HTML\n",
    "        html_content = str(soup)\n",
    "        file_name = f\"{sanitize_filename(url)}.html\"\n",
    "        with open(os.path.join(html_directory, file_name), 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        # Find all links on the page\n",
    "        for link in soup.find_all('a'):\n",
    "            # Get the absolute URL of the link\n",
    "            absolute_link = urljoin(url, link.get('href'))\n",
    "            \n",
    "            # Check if the link is within the same domain and has not been visited yet\n",
    "            if absolute_link.startswith(url) and absolute_link not in visited_pages:\n",
    "                # Recursively crawl the new page\n",
    "                crawl_website(absolute_link, visited_pages, max_depth - 1, html_directory)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url = 'https://ait.ac.th/' \n",
    "html_directory = 'html_files'\n",
    "os.makedirs(html_directory, exist_ok=True)\n",
    "crawl_website(url, html_directory=html_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "#!pip install unstructured\n",
    "\n",
    "# Make document from HTML file\n",
    "def make_document(html_directory):\n",
    "    documents = []\n",
    "    html_files = [os.path.join(html_directory, f) for f in os.listdir(html_directory) if f.endswith('.html')]\n",
    "    for file in html_files:\n",
    "        loader = UnstructuredHTMLLoader(file)\n",
    "        documents += loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = make_document(html_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all documents\n",
    "#documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of page\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Document Transformers\n",
    "\n",
    "Split the documents to smaller chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 25\n",
    ")\n",
    "\n",
    "doc = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies. AITâ€™s rigorous academic, research, and experiential outreach programs', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Text Embedding Models\n",
    "Embed the text by model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n",
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : device}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Vector Stores\n",
    "Create vector store to store embedded data and it perform vector search for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create path done\n"
     ]
    }
   ],
   "source": [
    "# Locate vectorstore\n",
    "vector_path = './vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vector locally\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents = doc,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "\n",
    "db_file_name = 'AIT'\n",
    "\n",
    "vectordb.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'ait' #default index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 retrievers\n",
    "A retriever is an interface that returns documents given an unstructured query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling vector from local\n",
    "vector_path = './vector-store'\n",
    "db_file_name = 'AIT'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'ait', #default index\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to use\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='documents from AIT.', metadata={'source': 'html_files\\\\https___ait_ac_th_study_open-master-of-engineering-science-in-interdisciplinary-studies-omis_.html'}),\n",
       " Document(page_content='Welcome to AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'}),\n",
       " Document(page_content='Home >\\n\\nAbout\\n\\nAbout AIT\\n\\nAIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\\n\\nIn this section\\n\\nAbout AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_about_.html'}),\n",
       " Document(page_content='AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies. AITâ€™s rigorous academic, research, and experiential outreach programs', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is AIT?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Computer Science (CS)\\n\\nConstruction, Engineering and Infrastructure Management (CEIM)\\n\\nData Science and AI (DSAI)\\n\\nDevelopment and Sustainability (DS)', metadata={'source': 'html_files\\\\https___ait_ac_th_academics_programs_.html'}),\n",
       " Document(page_content='Data Science and AI (DSAI)\\n\\nSchool of Environment, Resources, and Development (SERD)\\n\\nDEPARTMENT OF FOOD, AGRICULTURE AND BIORESOURCES\\n\\nAgribusiness Management (ABM)', metadata={'source': 'html_files\\\\https___ait_ac_th_study_flexible-masters-option_.html'}),\n",
       " Document(page_content='Data Science and AI (DSAI)\\n\\nSchool of Environment, Resources and Development (SERD)\\n\\nDEPARTMENT OF FOOD, AGRICULTURE, AND BIORESOURCES\\n\\nAgriBusiness Management (ABM)', metadata={'source': 'html_files\\\\https___ait_ac_th_study_flexible-phd-option_.html'}),\n",
       " Document(page_content='cooperation within the framework of DDAM, on the occasion of the 7 th DAAM international symposium to celebrate the 1000 th anniversary of Austria.', metadata={'source': 'html_files\\\\https___ait_ac_th_about_.html'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is DSAI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prompt\n",
    "\n",
    "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    I'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
    "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "PROMPT\n",
    "#using str.format \n",
    "#The placeholder is defined using curly brackets: {} {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    The Asian Institute of Technology (AIT) is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies. AITâ€™s rigorous academic, research, and experiential outreach programs prepare graduates for professional success and leadership roles in Asia and beyond.\\n    Question: What is AIT\\n    Answer:\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT.format(\n",
    "    context = \"The Asian Institute of Technology (AIT) is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies. AITâ€™s rigorous academic, research, and experiential outreach programs prepare graduates for professional success and leadership roles in Asia and beyond.\",\n",
    "    question = \"What is AIT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory\n",
    "\n",
    "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
    "\n",
    "You may want to use this class directly if you are managing memory outside of a chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message('hi')\n",
    "history.add_ai_message('Whats up?')\n",
    "history.add_user_message('How are you')\n",
    "history.add_ai_message('I\\'m quite good. How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Memory types\n",
    "\n",
    "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios. \n",
    "- Converstaion Buffer\n",
    "- Converstaion Buffer Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What variables get returned from memory\n",
    "\n",
    "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converstaion Buffer\n",
    "This memory allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the common way that we use\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content=\"What's up?\"),\n",
       "  HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm quite good. How about you?\")]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages = True)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer Window\n",
    "- it keeps a list of the interactions of the conversation over time. \n",
    "- it only uses the last K interactions. \n",
    "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1) #Keep last one\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Chain\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
    "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
    "- it formats the prompt template using the input key values provided (and also memory key values, if available), \n",
    "- it passes the formatted string to LLM and returns the LLM output.\n",
    "\n",
    "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create path done\n"
     ]
    }
   ],
   "source": [
    "#locate vectorstore\n",
    "vector_path = './models'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\earth\\AIT\\Sem2 23\\NLP\\Assignment\\A7\\NLP_A7_AIT_GPT_Chatbot\\models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastchat-t5-3b-v1.0'...\n",
      "Filtering content: 100% (2/2)\n",
      "Filtering content: 100% (2/2), 2.24 GiB | 5.72 MiB/s\n",
      "Filtering content: 100% (2/2), 2.24 GiB | 5.70 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "%cd ./models\n",
    "!git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "model_id = './models/fastchat-t5-3b-v1.0/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 256,\n",
    "    model_kwargs = {\n",
    "        \"temperature\" : 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
    "\n",
    "- `retriever` : Retriever to use to fetch documents.\n",
    "\n",
    "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
    "\n",
    "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
    "\n",
    "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
    "\n",
    "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
    "\n",
    "- `return_generated_question` : Return the generated question as part of the final result.\n",
    "\n",
    "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "Human:What is CS\n",
      "AI:\n",
      "Human:What s DSAI\n",
      "AI:\n",
      "Follow Up Input: Comparing both of them\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human:What is CS\\nAI:\\nHuman:What s DSAI\\nAI:',\n",
       " 'question': 'Comparing both of them',\n",
       " 'text': '<pad> What  is  the  difference  between  CS  and  DS  AI?\\n'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Comparing both of them'\n",
    "chat_history = \"Human:What is CS\\nAI:\\nHuman:What s DSAI\\nAI:\"\n",
    "\n",
    "question_generator({'chat_history' : chat_history, \"question\" : query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combine_docs_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x000001F283100690>)), document_variable_name='context')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    documents from AIT.\n",
      "\n",
      "Welcome to AIT\n",
      "\n",
      "Home >\n",
      "\n",
      "About\n",
      "\n",
      "About AIT\n",
      "\n",
      "AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\n",
      "\n",
      "In this section\n",
      "\n",
      "About AIT\n",
      "\n",
      "AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies. AITâ€™s rigorous academic, research, and experiential outreach programs\n",
      "    Question: What is AIT?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='documents from AIT.', metadata={'source': 'html_files\\\\https___ait_ac_th_study_open-master-of-engineering-science-in-interdisciplinary-studies-omis_.html'}),\n",
       "  Document(page_content='Welcome to AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'}),\n",
       "  Document(page_content='Home >\\n\\nAbout\\n\\nAbout AIT\\n\\nAIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\\n\\nIn this section\\n\\nAbout AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_about_.html'}),\n",
       "  Document(page_content='AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies. AITâ€™s rigorous academic, research, and experiential outreach programs', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'})],\n",
       " 'question': 'What is AIT?',\n",
       " 'output_text': '<pad> AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is AIT?\"\n",
    "input_document = retriever.get_relevant_documents(query)\n",
    "\n",
    "doc_chain({'input_documents':input_document, 'question':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x000001F283100690>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x000001F283100690>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x000001F2019344A0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001F205893910>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    Home >\n",
      "\n",
      "Privacy Policy\n",
      "\n",
      "Privacy Policy\n",
      "\n",
      "Who we are\n",
      "\n",
      "Our website address is https://ait.ac.th.\n",
      "\n",
      "you. We hope that will facilitate your personal and professional development.\n",
      "\n",
      "you. We hope that will facilitate your personal and professional development.\n",
      "\n",
      "Citizenship of an English speaking country. Applicants who are citizens of and have been educated in an English- speaking country (Australia, Canada, Ireland, New Zealand, the UK, and the USA) are\n",
      "    Question: Who are you by the way?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Who are you by the way?',\n",
       " 'chat_history': [],\n",
       " 'answer': \"<pad> I'm  AITBot,  a  chatbot  created  by  Noppawee  Teeraratchanon  to  assist  AIT  information  member  to  answer  the  question  people  may  have  about  AIT.  I'm  here  to  help  you  with  any  questions  you  may  have  about  AIT,  so  feel  free  to  ask  me  anything  you  need  help  with!\\n\",\n",
       " 'source_documents': [Document(page_content='Home >\\n\\nPrivacy Policy\\n\\nPrivacy Policy\\n\\nWho we are\\n\\nOur website address is https://ait.ac.th.', metadata={'source': 'html_files\\\\https___ait_ac_th_privacy-policy_.html'}),\n",
       "  Document(page_content='you. We hope that will facilitate your personal and professional development.', metadata={'source': 'html_files\\\\https___ait_ac_th_study_flexible-masters-option_.html'}),\n",
       "  Document(page_content='you. We hope that will facilitate your personal and professional development.', metadata={'source': 'html_files\\\\https___ait_ac_th_study_flexible-phd-option_.html'}),\n",
       "  Document(page_content='Citizenship of an English speaking country. Applicants who are citizens of and have been educated in an English- speaking country (Australia, Canada, Ireland, New Zealand, the UK, and the USA) are', metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Who are you by the way?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content=\"<pad> I'm  AITBot,  a  chatbot  created  by  Noppawee  Teeraratchanon  to  assist  AIT  information  member  to  answer  the  question  people  may  have  about  AIT.  I'm  here  to  help  you  with  any  questions  you  may  have  about  AIT,  so  feel  free  to  ask  me  anything  you  need  help  with!\\n\")]\n",
      "Follow Up Input: What is AIT?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    documents from AIT.\n",
      "\n",
      "Welcome to AIT\n",
      "\n",
      "Home >\n",
      "\n",
      "About\n",
      "\n",
      "About AIT\n",
      "\n",
      "AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\n",
      "\n",
      "In this section\n",
      "\n",
      "About AIT\n",
      "\n",
      "Explore AIT campus\n",
      "    Question: <pad>  What  is  AIT?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is AIT?',\n",
       " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content=\"<pad> I'm  AITBot,  a  chatbot  created  by  Noppawee  Teeraratchanon  to  assist  AIT  information  member  to  answer  the  question  people  may  have  about  AIT.  I'm  here  to  help  you  with  any  questions  you  may  have  about  AIT,  so  feel  free  to  ask  me  anything  you  need  help  with!\\n\")],\n",
       " 'answer': '<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n',\n",
       " 'source_documents': [Document(page_content='documents from AIT.', metadata={'source': 'html_files\\\\https___ait_ac_th_study_open-master-of-engineering-science-in-interdisciplinary-studies-omis_.html'}),\n",
       "  Document(page_content='Welcome to AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'}),\n",
       "  Document(page_content='Home >\\n\\nAbout\\n\\nAbout AIT\\n\\nAIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\\n\\nIn this section\\n\\nAbout AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_about_.html'}),\n",
       "  Document(page_content='Explore AIT campus', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"What is AIT?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content=\"<pad> I'm  AITBot,  a  chatbot  created  by  Noppawee  Teeraratchanon  to  assist  AIT  information  member  to  answer  the  question  people  may  have  about  AIT.  I'm  here  to  help  you  with  any  questions  you  may  have  about  AIT,  so  feel  free  to  ask  me  anything  you  need  help  with!\\n\"), HumanMessage(content='What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n')]\n",
      "Follow Up Input: Are there any scholarship\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    9. Do I need to apply for the scholarships listed on the AIT scholarship website?\n",
      "\n",
      "Yes, we have various forms of financial packages available to highly-qualified applicants from funds granted by donors as well as from AIT itself. Please check this site:Â Scholarships\n",
      "\n",
      "Yes, qualifying applicants will get the AIT Scholarship. Of course, if you can find an external scholarship to support yourself, you are more than welcome to take this opportunity during your\n",
      "\n",
      "Yes, qualifying applicants will get the AIT Scholarship. Of course, if you can find an external scholarship to support yourself, you are more than welcome to take this opportunity during your\n",
      "    Question: <pad>  Are  there  any  scholarships  available  for  students  at  AIT?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Are there any scholarship',\n",
       " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content=\"<pad> I'm  AITBot,  a  chatbot  created  by  Noppawee  Teeraratchanon  to  assist  AIT  information  member  to  answer  the  question  people  may  have  about  AIT.  I'm  here  to  help  you  with  any  questions  you  may  have  about  AIT,  so  feel  free  to  ask  me  anything  you  need  help  with!\\n\"),\n",
       "  HumanMessage(content='What is AIT?'),\n",
       "  AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n')],\n",
       " 'answer': '<pad> Yes,  we  have  various  forms  of  financial  packages  available  to  highly-qualified  applicants  from  funds  granted  by  donors  as  well  as  from  AIT  itself.  Please  check  this  site:\\n Scholarships\\n',\n",
       " 'source_documents': [Document(page_content='9. Do I need to apply for the scholarships listed on the AIT scholarship website?', metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'}),\n",
       "  Document(page_content='Yes, we have various forms of financial packages available to highly-qualified applicants from funds granted by donors as well as from AIT itself. Please check this site:\\xa0Scholarships', metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'}),\n",
       "  Document(page_content='Yes, qualifying applicants will get the AIT Scholarship. Of course, if you can find an external scholarship to support yourself, you are more than welcome to take this opportunity during your', metadata={'source': 'html_files\\\\https___ait_ac_th_study_flexible-masters-option_.html'}),\n",
       "  Document(page_content='Yes, qualifying applicants will get the AIT Scholarship. Of course, if you can find an external scholarship to support yourself, you are more than welcome to take this opportunity during your', metadata={'source': 'html_files\\\\https___ait_ac_th_study_flexible-phd-option_.html'})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Are there any scholarship\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Analyze the modelâ€™s performance in retrieving information.<br>\n",
    "    From the above 3 question, I think the AITBot answer quite good and relate to those question   \n",
    "2) Address any issues related to the model providing unrelated information.<br>\n",
    "    I observe that on question 2 (\"What is AIT?\"), there is one source document that unrelated which has content only \"Welcome to AIT\" and on question 1 (\"Who are you by the way?\") and question 3 (\"Are there any scholarship\").there are some source documents that have same content. it occur from the dataset that I have used on this assignment. I may address this issue by cleaning data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : 'cpu'}\n",
    ")\n",
    "\n",
    "\n",
    "#calling vector from local\n",
    "vector_path = '../vector-store'\n",
    "db_file_name = 'AIT'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'ait', #default index\n",
    ")   \n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    I'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
    "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "model_id = './fastchat-t5-3b-v1.0/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 256,\n",
    "    model_kwargs = {\n",
    "        \"temperature\" : 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)\n",
    "\n",
    "\n",
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content=' What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n'), HumanMessage(content='Are there any scholarship'), AIMessage(content='<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\\n'), HumanMessage(content='Are there any scholarship'), AIMessage(content='<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\\n')]\n",
      "Follow Up Input:  What is AIT?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    documents from AIT.\n",
      "\n",
      "Welcome to AIT\n",
      "\n",
      "Home >\n",
      "\n",
      "About\n",
      "\n",
      "About AIT\n",
      "\n",
      "AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\n",
      "\n",
      "In this section\n",
      "\n",
      "About AIT\n",
      "\n",
      "Explore AIT campus\n",
      "    Question: <pad> What  is  AIT?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Are there any scholarship'), AIMessage(content='<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\\n'), HumanMessage(content='Are there any scholarship'), AIMessage(content='<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\\n'), HumanMessage(content=' What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n')]\n",
      "Follow Up Input:  What is AIT?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    documents from AIT.\n",
      "\n",
      "Welcome to AIT\n",
      "\n",
      "Home >\n",
      "\n",
      "About\n",
      "\n",
      "About AIT\n",
      "\n",
      "AIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\n",
      "\n",
      "In this section\n",
      "\n",
      "About AIT\n",
      "\n",
      "Explore AIT campus\n",
      "    Question: <pad> What  is  AIT?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\n",
      "\n",
      "[Document(page_content='documents from AIT.', metadata={'source': 'html_files\\\\https___ait_ac_th_study_open-master-of-engineering-science-in-interdisciplinary-studies-omis_.html'}), Document(page_content='Welcome to AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'}), Document(page_content='Home >\\n\\nAbout\\n\\nAbout AIT\\n\\nAIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\\n\\nIn this section\\n\\nAbout AIT', metadata={'source': 'html_files\\\\https___ait_ac_th_about_.html'}), Document(page_content='Explore AIT campus', metadata={'source': 'html_files\\\\https___ait_ac_th_.html'})]\n"
     ]
    }
   ],
   "source": [
    "search_query = \" What is AIT?\"\n",
    "answer = chain({\"question\":search_query})['answer']\n",
    "source = chain({\"question\":search_query})['source_documents']\n",
    "print(answer)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\n",
      "\n",
      "1 page_content='documents from AIT.' metadata={'source': 'html_files\\\\https___ait_ac_th_study_open-master-of-engineering-science-in-interdisciplinary-studies-omis_.html'}\n",
      "2 page_content='Welcome to AIT' metadata={'source': 'html_files\\\\https___ait_ac_th_.html'}\n",
      "3 page_content='Home >\\n\\nAbout\\n\\nAbout AIT\\n\\nAIT is an international English-speaking postgraduate institution, focusing on engineering, environment, and management studies.\\n\\nIn this section\\n\\nAbout AIT' metadata={'source': 'html_files\\\\https___ait_ac_th_about_.html'}\n",
      "4 page_content='Explore AIT campus' metadata={'source': 'html_files\\\\https___ait_ac_th_.html'}\n"
     ]
    }
   ],
   "source": [
    "print(answer)\n",
    "for i,doc in enumerate(source):\n",
    "    print(i+1,doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Are there any scholarship'), AIMessage(content='<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\\n'), HumanMessage(content=' What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n'), HumanMessage(content=' What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n')]\n",
      "Follow Up Input: Are there any scholarship\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    AIT offers a limited number of financial awards in the form of scholarships for the Masterâ€™s and Doctoral programs, on a highly competitive basis, to applicants who have been evaluated as\n",
      "\n",
      "9. Do I need to apply for the scholarships listed on the AIT scholarship website?\n",
      "\n",
      "Yes, we have academic exchange programs with various partner universities in Asia and Europe. AIT has a limited number of scholarships to assist our students to go on academic exchange. You can apply\n",
      "\n",
      "Yes, we have various forms of financial packages available to highly-qualified applicants from funds granted by donors as well as from AIT itself. Please check this site:Â Scholarships\n",
      "    Question: <pad> Are  there  any  scholarships  available  for  postgraduate  studies  at  AIT?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content=' What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n'), HumanMessage(content=' What is AIT?'), AIMessage(content='<pad> < pad>  AIT  is  an  international  English-speaking  postgraduate  institution,  focusing  on  engineering,  environment,  and  management  studies.\\n'), HumanMessage(content='Are there any scholarship'), AIMessage(content='<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\\n')]\n",
      "Follow Up Input: Are there any scholarship\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly chatbot named AITBot created by Noppawee Teeraratchanon, here to assist AIT information member to answer the question people may have about AIT.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    AIT offers a limited number of financial awards in the form of scholarships for the Masterâ€™s and Doctoral programs, on a highly competitive basis, to applicants who have been evaluated as\n",
      "\n",
      "9. Do I need to apply for the scholarships listed on the AIT scholarship website?\n",
      "\n",
      "Yes, we have academic exchange programs with various partner universities in Asia and Europe. AIT has a limited number of scholarships to assist our students to go on academic exchange. You can apply\n",
      "\n",
      "Yes, we have various forms of financial packages available to highly-qualified applicants from funds granted by donors as well as from AIT itself. Please check this site:Â Scholarships\n",
      "    Question: <pad> Are  there  any  scholarships  available  for  postgraduate  studies  at  AIT?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "search_query = \"Are there any scholarship\"\n",
    "answer = chain({\"question\":search_query})['answer']\n",
    "source = chain({\"question\":search_query})['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Yes,  there  are  several  scholarships  available  for  postgraduate  studies  at  AIT.  Please  check  the  scholarship  website  for  more  information.\n",
      "\n",
      "1 page_content='AIT offers a limited number of financial awards in the form of scholarships for the Masterâ€™s and Doctoral programs, on a highly competitive basis, to applicants who have been evaluated as' metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'}\n",
      "2 page_content='9. Do I need to apply for the scholarships listed on the AIT scholarship website?' metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'}\n",
      "3 page_content='Yes, we have academic exchange programs with various partner universities in Asia and Europe. AIT has a limited number of scholarships to assist our students to go on academic exchange. You can apply' metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'}\n",
      "4 page_content='Yes, we have various forms of financial packages available to highly-qualified applicants from funds granted by donors as well as from AIT itself. Please check this site:\\xa0Scholarships' metadata={'source': 'html_files\\\\https___ait_ac_th_admissions_frequently-asked-questions_.html'}\n"
     ]
    }
   ],
   "source": [
    "print(answer)\n",
    "for i,doc in enumerate(source):\n",
    "    print(i+1,doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
